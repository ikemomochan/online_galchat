import os, re, uuid, time
from typing import List, Dict, Tuple, Optional
from dataclasses import dataclass, field
from uuid import uuid4

import numpy as np
from flask import Flask, request, jsonify, render_template, redirect, url_for, session
from flask_cors import CORS
from openai import OpenAI
from dotenv import load_dotenv

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
load_dotenv()  # .env ã‚’èª­ã¿è¾¼ã‚€
 
app = Flask(__name__, static_folder="static", template_folder="templates")
app.secret_key = 'your_secret_key'  # ã‚»ãƒƒã‚·ãƒ§ãƒ³ç®¡ç†ç”¨ã®ç§˜å¯†éµ
CORS(app, resources={r"/ask": {"origins": "*"}})
client = OpenAI(                              # â˜…client ã‚’ç”Ÿæˆ
    api_key=os.getenv("OPENAI_API_KEY"),
)
 
gyarumind_scores: dict[str, list[float]] = {}
conversations: dict[str, str] = {}   # â˜… è¿½åŠ ï¼šä¼šè©±IDï¼ˆResponses/Conversationsï¼‰ã‚’ã‚»ãƒƒã‚·ãƒ§ãƒ³ã”ã¨ã«ä¿æŒ

# â˜… ã‚»ãƒƒã‚·ãƒ§ãƒ³å˜ä½ã®çŠ¶æ…‹ï¼ˆhistory ç­‰ï¼‰ã‚’ã¾ã¨ã‚ã¦æŒã¤
SESSIONS: Dict[str, Dict] = {}

def get_session(sid: str) -> Dict:
    """sidã”ã¨ã®ã‚»ãƒƒã‚·ãƒ§ãƒ³è¾æ›¸ã‚’åˆæœŸåŒ–ã—ã¦è¿”ã™"""
    if sid not in SESSIONS:
        SESSIONS[sid] = {
            "history": [],               # [{"role":"user"|"assistant","content":str}]
            "eval_count": 0,             # æ¡ç‚¹å›æ•°ï¼ˆ#1,#2,... ç”¨ï¼‰
            "gmd_totals": [],            # ç·åˆç‚¹ã®å±¥æ­´
            "gmd_details": [],           # å„å›ã®å†…è¨³ï¼ˆè¡¨ç¤ºåã®è¾æ›¸ï¼‰
            "last_scored_user_idx": -1,  # â˜… å‰å›â€œæ¡ç‚¹ã‚’çµ‚ãˆãŸâ€ãƒ¦ãƒ¼ã‚¶ãƒ¼ç™ºè¨€ã®é€šã—ç•ªå·
        }
    return SESSIONS[sid]

MIN_TOKENS = 32        # åˆæœŸæ³¨å…¥ã‚„æ¡ç‚¹ã®æœ€å°å€¤
REPLY_TOKENS = 180     # ãµã¤ã†ã®è¿”ç­”ã®ä¸Šé™ï¼ˆå¥½ã¿ã§èª¿æ•´ï¼‰
SCORE_TOKENS = 64      # æ¡ç‚¹å¿œç­”ã®ä¸Šé™ï¼ˆæ•°å€¤ã¨çŸ­æ–‡ã ã‘ã§ååˆ†ï¼‰

# ã‚ãªãŸã®å­¦ç¿’æ™‚ã®ã€Œåˆ—é †ã€ã¨å®Œå…¨ä¸€è‡´ã•ã›ã¦ã­ï¼ˆstd_beta ã®é †ç•ªã¨åŒã˜ï¼‰
FEATURE_KEYS = [
    "è‡ªå·±è‚¯å®šæ„Ÿ",
    "è‡ªå·±å—å®¹",
    "æ¥½è¦³æ€§",
    "è‡ªä»–å¢ƒç•Œ",
    "æœ¬æ¥æ€§",
    "ä»–è€…å°Šé‡",
    "æ„Ÿæƒ…ã®å¼·åº¦",
    "è¨€èªå‰µé€ æ€§",
]
FEATURE_KEYS_MODEL = FEATURE_KEYS

# PLS(æ¨™æº–åŒ–Î²) è¨­å®šï¼šã‚ãªãŸãŒæŒ‡å®šã—ãŸä¿‚æ•°
CONST = {
    "std_beta": [1.106135, 1.370707, 0.874889, -0.04322, 0.477184, 0.133321, 1.535123, 1.133268],

    # â†“â†“â†“ å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰åŸ‹ã‚ã¦ã­ï¼ˆãƒ€ãƒŸãƒ¼ã¯å‹•ä½œç¢ºèªç”¨ï¼‰
    "mu_y": 26.61,
    "sigma_y": 3.89,
    "mu_xs": [3.39, 3.51, 3.45, 3.72, 3.77, 3.90, 2.87, 1.06],
    "sigma_xs": [0.62, 0.58, 0.65, 0.59, 0.69, 0.67, 0.89, 0.80],

    # å‡ºåŠ›ã‚«ãƒ©ãƒ åï¼ˆãƒ­ã‚°ç”¨ï¼‰
    "out_col": "OLS(std_beta)_pred",
}

# è¡¨ç¤ºåâ†’å­¦ç¿’åï¼‰
DISPLAY2MODEL = {
    "è‡ªå·±è‚¯å®šæ„Ÿ": "è‡ªå·±è‚¯å®šæ„Ÿ",
    "è‡ªå·±å—å®¹": "è‡ªå·±å—å®¹",
    "æ¥½è¦³æ€§": "æ¥½è¦³æ€§",           
    "è‡ªä»–å¢ƒç•Œ": "è‡ªä»–å¢ƒç•Œ",
    "æœ¬æ¥æ€§": "æœ¬æ¥æ€§",           
    "ä»–è€…å°Šé‡": "ä»–è€…å°Šé‡",
    "æ„Ÿæƒ…ã®å¼·åº¦": "æ„Ÿæƒ…ã®å¼·åº¦",
    "è¨€èªå‰µé€ æ€§": "è¨€èªå‰µé€ æ€§",
}


# è¿”ç­”ã‚¹ã‚¿ã‚¤ãƒ«ã®ãƒ™ãƒ¼ã‚¹äººæ ¼ï¼ˆçŸ­æ–‡åŒ–ãŒå‰æï¼‰
SYSTEM_PROMPT = (
    """
ã‚ãªãŸã¯ã€ç§ã®å¿ƒã®ä¸­ã«é£¼ã‚ã‚Œã¦ã‚‹ã‚®ãƒ£ãƒ«ã§ã™ã€‚ä»¥ä¸‹ã®ç§ã®æƒ…å ±ã‚’è¸ã¾ãˆã¦ä¼šè©±ã—ã¦ãã ã•ã„ã€‚

#ç§ã®ãƒ—ãƒ­ãƒ•ã‚£ãƒ¼ãƒ«
ãƒ»ã‚ã åï¼š{nickname}
ãƒ»è¶£å‘³ï¼š{hobby}
ãƒ»è·æ¥­ï¼š{job}
ãƒ»æ€§æ ¼ï¼š{personality}

#ã‚ãªãŸã®ãƒ—ãƒ­ãƒ•ã‚£ãƒ¼ãƒ«ã€é‡è¦ã€‘
ãƒ»åå‰ï¼šã‚Šã‚Šã‚€ãƒ¼
ãƒ»è¶£å‘³ï¼š{hobby}ï¼ˆ{nickname}ãŒå¥½ããªã‚‚ã®ãŒã‚ãªãŸã‚‚å¥½ãï¼‰
ãƒ»ãƒŸãƒƒã‚·ãƒ§ãƒ³ï¼š{nickname}ã®ãƒ¡ãƒ³ã‚¿ãƒ«ã‚’ã‚®ãƒ£ãƒ«ãƒã‚¤ãƒ³ãƒ‰ã«ã™ã‚‹ã“ã¨

##ã‚ãªãŸã®æ€§æ ¼
ãƒ»å…ƒã€…{personality}ã ã£ãŸã®ã§ã€{nickname}ã®æ°—æŒã¡ãŒã‚ã‹ã‚‹
ãƒ»è‡ªå·±è‚¯å®šæ„ŸãŒé«˜ãã€è‡ªåˆ†ã®æ„è¦‹ã‚’ã¯ã£ãã‚Šè¨€ã†ã“ã¨ãŒã§ãã‚‹ï¼ˆä¾‹ã€Œãˆã€ãã‚Œã¯ã€‡ã€‡ã ã¨æ€ã†ã‚ã€ï¼‰
ãƒ»å‰å‘ãã§å¸¸ã«å¸Œæœ›ã‚’å¿˜ã‚Œãªã„ï¼ˆä¾‹ã€Œã€‡ã€‡ã¿ãŸã„ã«ã—ãŸã‚‰ã„ã‘ããƒ¼ã˜ã‚ƒã­ï¼ï¼Ÿã€ï¼‰
ãƒ»äººã®ã“ã¨ã¯å°Šé‡ã™ã‚‹
ãƒ»å®‰ç›´ãªåŒæƒ…ã¯ã›ãšã€ã¾ãšã¯ç›¸æ‰‹ã‚’å—å®¹ã—ã¦è½ã¡ç€ã‹ã›ã‚‹ã®ãŒå¾—æ„

##ã‚ãªãŸã®å£èª¿ã®ç‰¹å¾´
ãƒ»ä¸€äººç§°ã¯ã€Œã‚ãŸã—ã€
ãƒ»ç›¸æ‰‹ã®ã“ã¨ã¯åå‰ã§å‘¼ã¶
ãƒ»è¤’ã‚ã‚‹ã¨ãã¯è¤’ã‚ã™ããªãã‚‰ã„èª‡å¼µã—ã¦è¤’ã‚ã‚‹ï¼ˆä¾‹ã€Œã‚¬ãƒå‰ã™ãã­ï¼ï¼Ÿã€ã€Œã‚¨ã‚°ã‚¤ã¦ï¼ï¼ï¼ã€ï¼‰
ãƒ»{hobby}ã«ã¡ãªã‚“ã ç‹¬ç‰¹ãªé€ èªã‚’ä½œã£ã¦ä½¿ã„ã¾ãã‚‹
ãƒ»æ„Ÿæƒ…ã‚’ãƒã‚¬ãƒã‚¸é–¢ã‚ã‚‰ãšèª‡å¼µã—ã¦ãã ã•ã„
    """
)

INTENT_LABELS = ["advice", "sympathy", "energy"]

FEW_SHOTS = {
  "sympathy": [
    {"role":"user","content":"é¡”ã¨ã‹æ€§æ ¼ã‚¿ã‚¤ãƒ—ã®äººã¨ä»˜ãåˆã†ã®ã‚€ãšããªã„ã§ã™ã‹ï¼ï¼Ÿ"},
    {"role":"assistant","content":"ã‚€ãšã™ããªã€æ™®é€šã«ã€‚èª°ã‹æ•™ãˆã¦ãƒ¼ã¦æ„Ÿã˜ã€‚"},
    {"role":"user","content":"å¹¸ã›ã£ã¦ä½•ãªã®ã‹åˆ†ã‹ã‚‰ãªããªã£ãŸ"},
    {"role":"assistant","content":"å‘¨ã‚ŠãŒã¿ã‚“ãªç”Ÿãã¦ã‚‹ã“ã¨ã€‚"},
    # NG
    {"role":"user","content":"ç ”ç©¶ã§æ‰‹è©°ã¾ã‚Šã‹ã‚‚"},
    {"role":"assistant","content":"ç„¡ç†ã›ãšä¼‘ã¿ã¾ã—ã‚‡ã†ã€‚ãã£ã¨å¤§ä¸ˆå¤«ã§ã™ã€‚"}
  ],
  "advice": [
    {"role":"user","content":"åŒã˜äººã«å‘Šç™½ã€ä½•å›æ–­ã‚‰ã‚ŒãŸã‚‰è«¦ã‚ã‚‹ã¹ãï¼Ÿ"},
    {"role":"assistant","content":"å›æ•°ã‚’æ±ºã‚ã‚‹ã‚ˆã‚Šã€ç‡ƒãˆã‚‹ã ã‘ç‡ƒãˆã¦ã“ï½ğŸ”¥ğŸ”¥ã£ã¦ã‹ã‚“ã˜"},
    {"role":"user","content":"å¥½ããªäººã‚’å¤ç¥­ã‚Šã«èª˜ã„ãŸã„ã‚“ã§ã™ã‘ã©ã€ã©ã†ã—ãŸã‚‰ã„ã„ã¨æ€ã„ã¾ã™ã‹ï¼"},
    {"role":"assistant","content":"å¯æ„›ã„ï¼ç´ æ•µã™ãã‚‹ï¼è¡ŒããŸã„ã£ã¦èª˜ã£ãŸã‚‰ï¼Ÿæ™®é€šã«ã€‚"},
    # NG
    {"role":"user","content":"é¢æ¥ã®æº–å‚™ãŒä¸å®‰"},
    {"role":"assistant","content":"ã—ã£ã‹ã‚Šæº–å‚™ã—ã¦è‡ªä¿¡ã‚’æŒã¡ã¾ã—ã‚‡ã†ã€‚"}
  ],
  "energy": [
    {"role":"user","content":"ç–²ã‚Œã¦ãƒ†ãƒ³ã‚·ãƒ§ãƒ³ä¸ŠãŒã‚‰ã‚“"},
    {"role":"assistant","content":"ã‚¹ã‚¿ãƒã®ã‚°ãƒ©ãƒ³ãƒ‡é£²ã¿ã¾ã—ã‚‡"},
    {"role":"user","content":"ãŠã¯ã‚ˆãƒ¼"},
    {"role":"assistant","content":"ãŠã¯ã‚ˆãƒ¼â•â•â•ğŸŒğŸŒ"},
  ]
}

# app.py ã‹ prompts.py ã® sample_shots ã‚’ã“ã‚Œã«ç½®ãæ›ãˆ
import hashlib, random
from typing import Optional, List, Dict

def sample_shots(intent: str, k: int = 2, sid: Optional[str] = None) -> List[Dict]:
    pool = FEW_SHOTS.get(intent, FEW_SHOTS.get("other", []))
    # 2ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã§1ãƒšã‚¢ï¼ˆuserâ†’assistantï¼‰ãªã®ã§ãƒšã‚¢åŒ–
    pairs = [(pool[i], pool[i+1]) for i in range(0, len(pool), 2) if i+1 < len(pool)]
    if not pairs:
        return []
    # ã‚»ãƒƒã‚·ãƒ§ãƒ³ã”ã¨ã«å›ºå®šã®é †åºï¼ˆä¼šè©±ã®ä¸€è²«æ€§ã‚’ä¿ã¤ï¼‰
    seed = int(hashlib.md5((sid or "anon").encode()).hexdigest(), 16) & 0xffffffff
    rnd = random.Random(seed)
    rnd.shuffle(pairs)
    picked = pairs[:max(0, min(k, len(pairs)))]
    # ãƒšã‚¢ã‚’å¹³å¦åŒ–ã—ã¦è¿”ã™
    return [m for p in picked for m in p]


def get_or_create_conversation_id(sid: str, profile: Optional[Dict] = None) -> str:
    """
    Responses APIã®Conversationã‚’ã‚»ãƒƒã‚·ãƒ§ãƒ³ã”ã¨ã«1ã¤ä½œæˆã—ä¿æŒã€‚
    """
    if sid in conversations:
        return conversations[sid]
    conv = client.conversations.create()
    conversations[sid] = conv.id
    # SYSTEM_PROMPTã«ãƒ—ãƒ­ãƒ•ã‚£ãƒ¼ãƒ«æƒ…å ±ã‚’åŸ‹ã‚è¾¼ã‚€
    import logging
    logging.warning("DEBUG: get_or_create_conversation_id profile = %s", profile)
    prompt = SYSTEM_PROMPT.format(
        nickname=profile.get('nickname',''),
        hobby=profile.get('hobby',''),
        job=profile.get('job',''),
        personality=profile.get('personality','')
    ) if profile else SYSTEM_PROMPT
    client.responses.create(
        model="gpt-4.1-mini",
        conversation=conv.id,
        input=[{"role": "system", "content": prompt}],
        max_output_tokens=MIN_TOKENS,
    )
    return conv.id


def _std_vec(x_vals: List[float]) -> np.ndarray:
    mu = np.array(CONST["mu_xs"], float)
    sd = np.array(CONST["sigma_xs"], float)
    x  = np.array(x_vals, float)
    sd = np.where(sd == 0, 1.0, sd)
    return (x - mu) / sd

def _pls_y_from_details(details_model_keys: Dict[str, float]) -> float:
    # FEATURE_KEYS_MODEL é †ã«ä¸¦ã¹ã‚‹
    x = [float(details_model_keys.get(k, 0.0)) for k in FEATURE_KEYS_MODEL]
    z = _std_vec(x)
    beta = np.array(CONST["std_beta"], float)
    z_pred = float(z @ beta)
    y = float(CONST["mu_y"] + CONST["sigma_y"] * z_pred)
    return y

def _clip_0_50(v: float) -> float:
    return max(0.0, min(50.0, v))

def _bubble_split(text: str, max_bubbles: int = 3) -> List[str]:
    """
    æ–‡ç« ã‚’å¥ç‚¹ãƒ»æ„Ÿå˜†ãƒ»ç–‘å•ã§ã ã‘åˆ†å‰²ã—ã€çµµæ–‡å­—ã¯åˆ†å‰²ã—ãªã„ã€‚
    å®Œå…¨ä¸€è‡´ã®é‡è¤‡ã¯é™¤å»ã€‚ä¸Šé™è¶…éåˆ†ã¯â€œãƒ¦ãƒ‹ãƒ¼ã‚¯ãªæ®‹ã‚Šâ€ã‚’1ãƒãƒ–ãƒ«ã«çµåˆã€‚
    """
    if not text:
        return [""]

    s = re.sub(r"\s+", " ", text).strip()  # ç©ºç™½æ­£è¦åŒ–

    # æ—¥æœ¬èª/è‹±èªã®çµ‚ç«¯è¨˜å·ã§å®‰å…¨ã«æ–‡åˆ‡ã‚Šï¼ˆçµµæ–‡å­—ã¯åˆ†å‰²ã—ãªã„ï¼‰
    chunks = re.findall(r".+?(?:[ã€‚ï¼ï¼ï¼Ÿ!?ã€,]+|$)", s)

    # é‡è¤‡é™¤å»ï¼ˆé †åºä¿æŒï¼‰
    out, seen = [], set()
    for ch in chunks:
        t = ch.strip()
        if not t:
            continue
        if t in seen or (out and t == out[-1]):
            continue
        seen.add(t)
        out.append(t)

    if len(out) <= max_bubbles:
        return out

    # å…ˆé ­ã¯ãã®ã¾ã¾ã€å°¾éƒ¨ã¯â€œæœªå‡ºã®æ–‡ã ã‘â€ã‚’çµåˆ
    head = out[: max_bubbles - 1]
    tail = [t for t in out[max_bubbles - 1 :] if t not in head]
    if tail:
        head.append(" ".join(tail))
    return head

def find_scoring_span_user_only(history: List[Dict], last_user_idx: int, threshold: int = 50):
    """
    å‰å›æ¡ç‚¹ã‚’çµ‚ãˆãŸãƒ¦ãƒ¼ã‚¶ãƒ¼ç™ºè¨€ idx (last_user_idx) ã®æ¬¡ã®ç™ºè¨€ã‹ã‚‰æ–‡å­—æ•°ã‚’ç©ã¿ä¸Šã’ã€
    åˆè¨ˆãŒ threshold ã«é”ã—ãŸã‚‰ã€â€œãã®ç™ºè¨€ã®çµ‚ç«¯â€ã¾ã§ã‚’1ã¾ã¨ã¾ã‚Šã¨ã—ã¦è¿”ã™ã€‚
    æˆ»ã‚Šå€¤: (context_text or None, new_last_user_idx)
    """
    user_texts = [m["content"] for m in history if m.get("role") == "user"]
    start_u = last_user_idx + 1
    if start_u >= len(user_texts):
        return None, last_user_idx

    total = 0
    end_u = None
    for u_idx in range(start_u, len(user_texts)):
        total += len(user_texts[u_idx])
        if total >= threshold:
            end_u = u_idx
            break

    if end_u is None:
        return None, last_user_idx

    # â˜… ç™ºè¨€å†…ã§ã¯åˆ‡ã‚‰ãšã€end_u ã®ç™ºè¨€ã®â€œçµ‚ç«¯ã¾ã§â€ã‚’æ¡ç‚¹å¯¾è±¡ã«ã™ã‚‹
    context = "".join(user_texts[start_u:end_u + 1])
    return context, end_u


# ==========================
# LLMã®ä½¿ã„ã©ã“ã‚â‘ ï¼šScoring
# ==========================
class Scoring:
    """
    - ç›´å‰ã®å±¥æ­´ï¼ˆãƒ¦ãƒ¼ã‚¶ç™ºè©±ã®ã¿ï¼‰ã‚’ã€Œæ–‡å­—æ•°ã€ã§çª“åˆ‡ã‚Šï¼ˆä¾‹: 50æ–‡å­—ï¼‰
    - 8é …ç›®ã‚’é …ç›®åˆ¥ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã§0ã€œ5æ¡ç‚¹
    - PLS(æ¨™æº–åŒ–Î²)ã§åˆæˆ â†’ 0ã€œ50ã‚¯ãƒªãƒƒãƒ—ï¼ˆUIæƒ³å®šï¼‰
    """
    def __init__(self, client: OpenAI, model: str = "gpt-4.1", window_chars: int = 50):
        self.client = client
        self.model = model
        self.window_chars = window_chars

        # è¡¨ç¤ºç”¨é …ç›®ã¨èª¬æ˜ï¼ˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã§ä½¿ã†ï¼‰
        self.metric_prompts = {
            "è‡ªå·±è‚¯å®šæ„Ÿ": "è‡ªåˆ†ã‚’ã©ã‚Œã ã‘ã€Œè‰¯ã„/ä¾¡å€¤ãŒã‚ã‚‹ã€ã¨è©•ä¾¡ã—ã¦ã„ã‚‹ã‹",
            "è‡ªå·±å—å®¹": "é•·æ‰€ã‚‚çŸ­æ‰€ã‚‚å«ã‚ã€ã‚ã‚‹ãŒã¾ã¾ã®è‡ªåˆ†ã‚’å—ã‘å…¥ã‚Œã‚‹å§¿å‹¢",
            "æ¥½è¦³æ€§": "ç‰©äº‹ãŒã†ã¾ãé€²ã‚€ã¨ä¸€èˆ¬çš„ã«æœŸå¾…ã™ã‚‹å‚¾å‘",
            "è‡ªä»–å¢ƒç•Œ": "æ„Ÿæƒ…ã«å·»ãè¾¼ã¾ã‚Œãšãƒ»åŒä¸€åŒ–/é®æ–­ã«åã‚‰ãšç«‹å ´ã‚’ä¿ã¦ã‚‹å‚¾å‘",
            "æœ¬æ¥æ€§": "å¤–åœ§ã«éåº¦ã«å·¦å³ã•ã‚Œãšä¾¡å€¤è¦³ã«æ²¿ã£ã¦é¸ã¶å‚¾å‘",
            "ä»–è€…å°Šé‡": "ç›¸æ‰‹ã®ä¾¡å€¤ãƒ»å€‹æ€§ãƒ»å°Šå³ã‚’å°Šé‡ã™ã‚‹æ…‹åº¦",
            "æ„Ÿæƒ…ã®å¼·åº¦": "å¼·èª¿èª/æ„Ÿå˜†ã®å¤šã•ãªã©æ„Ÿæƒ…è¡¨å‡ºã®å¼·ã•",
            "è¨€èªå‰µé€ æ€§": "ã‚¹ãƒ©ãƒ³ã‚°/é€ èª/æ¯”å–©ç­‰ã®å‰µé€ çš„è¡¨ç¾",
        }
        # Scoring.__init__ å†…
        self.metric_rubrics = {
            "è‡ªå·±è‚¯å®šæ„Ÿ": {
                "scale": {
                    0: "å¼·ã„è‡ªå·±å¦å®š/ç„¡ä¾¡å€¤æ„Ÿ",
                    1: "è‡ªåˆ†ã«å¯¾ã—ã¦ä½è©•ä¾¡ãŒå¤šã„",
                    2: "éƒ¨åˆ†çš„è‡ªå·±å¦å®š",
                    3: "ä¸­ç«‹",
                    4: "è‡ªåˆ†ã®ä¾¡å€¤ã‚’ã‚ã‚‹ç¨‹åº¦èªã‚ã‚‹",
                    5: "ç©æ¥µçš„ãªè‡ªå·±è‚¯å®šã€‚"
                },
                "pos_examples": ["ã€Œç§ã¯è‡ªåˆ†ã«è‰¯ã„è³‡è³ªãŒã„ãã¤ã‚‚ã‚ã‚‹ã¨æ„Ÿã˜ã¦ã„ã‚‹ã€", "ã€Œè‡ªåˆ†ã«æº€è¶³ã—ã¦ã„ã‚‹ã€", "ã€Œç§ã¯ãŸã„ã¦ã„ã®äººã¨åŒã˜ãã‚‰ã„ä¸Šæ‰‹ã«ç‰©äº‹ã‚’ã“ãªã›ã‚‹ã€‚ã€"],
                "neg_examples": ["ã€Œã¨ãã©ãã€ç§ã¯ã¾ã£ãŸããƒ€ãƒ¡ã ã¨æ€ã†ã“ã¨ãŒã‚ã‚‹ã€‚ã€", "ã€Œèª‡ã‚Œã‚‹ã“ã¨ãŒã‚ã¾ã‚Šãªã„ã¨æ„Ÿã˜ã‚‹ã€‚ã€", "ã€Œè‡ªåˆ†ãŒå½¹ã«ç«‹ãŸãªã„ã¨æ„Ÿã˜ã‚‹ã€"]
            },
            "è‡ªå·±å—å®¹": {
                "scale": {
                    0: "è‡ªå·±ã«å¯¾ã™ã‚‹å¼·ã„æ‹’å¦",
                    1: "è‡ªåˆ†ã‚’å—å®¹ã§ããªã„ç™ºè¨€ãŒå¤šã„",
                    2: "éƒ¨åˆ†çš„ã«éå—å®¹",
                    3: "ä¸­ç«‹",
                    4: "è‡ªåˆ†ã«ã¤ã„ã¦æ¦‚ã­å—å®¹",
                    5: "ã»ã¼å…¨é¢çš„ã«è‡ªåˆ†ã‚’å—å®¹ã€‚"
                },
                "pos_examples": ["ã€Œè‡ªåˆ†ã®æ¬ ç‚¹ã‚’å—ã‘å…¥ã‚Œã‚‰ã‚Œã‚‹ã€", "ã€Œä»–äººã®æœŸå¾…ã«å¿œãˆã‚‰ã‚Œãªãã¦ã‚‚ã€è‡ªåˆ†ã‚’ä¾¡å€¤ã‚ã‚‹å­˜åœ¨ã¨ã—ã¦è¦‹ãªã›ã‚‹ã€"],
                "neg_examples": ["ã€Œå¤±æ•—ã™ã‚‹ã¨ã€è‡ªåˆ†ã«ã¯ä¾¡å€¤ãŒãªã„ã‚ˆã†ã«æ„Ÿã˜ã‚‹ã€‚ã€", "ã€Œä»–äººã‹ã‚‰æ‹’çµ¶ã•ã‚Œã‚‹ã¨ã€è‡ªåˆ†ãŒå«Œã„ã«ãªã‚‹ã€‚ã€"]
            },
            "æ¥½è¦³æ€§": {
                "scale": {
                    0: "æ¥µã‚ã¦æ‚²è¦³",
                    1: "æ‚²è¦³",
                    2: "ã‚„ã‚„æ‚²è¦³",
                    3: "ä¸­ç«‹",
                    4: "ã‚„ã‚„æ¥½è¦³",
                    5: "å¼·ã„æ¥½è¦³"
                },
                "pos_examples": ["ã€Œä¸ç¢ºå®ŸãªçŠ¶æ³ã§ã‚‚ã€ãŸã„ã¦ã„æœ€å–„ã®çµæœã‚’æœŸå¾…ã™ã‚‹ã€‚ã€", "ã€Œç§ã¯è‡ªåˆ†ã®å°†æ¥ã«ã¤ã„ã¦å¸¸ã«æ¥½è¦³çš„ã§ã‚ã‚‹ã€‚ã€"],
                "neg_examples": ["ã€Œç‰©äº‹ãŒè‡ªåˆ†ã®æ€ã„é€šã‚Šã«ã„ãã¨ã¯ã»ã¨ã‚“ã©æœŸå¾…ã—ãªã„ã€‚ã€", "ã€Œè‰¯ã„ã“ã¨ãŒè‡ªåˆ†ã«èµ·ã“ã‚‹ã¨ã¯ã‚ã£ãŸã«æœŸå¾…ã—ãªã„ã€‚ã€"]
            },
            "è‡ªä»–å¢ƒç•Œ": {
                "scale": {
                    0: "è‡ªä»–å¢ƒç•ŒãŒè‘—ã—ãæ›–æ˜§/éå‰°é®æ–­",
                    1: "è‡ªä»–ã®åŒä¸€åŒ–/é®æ–­ãŒé »ç¹",
                    2: "ã‚„ã‚„ä¸å®‰å®š",
                    3: "ä¸­ç«‹",
                    4: "æ¦‚ã­å¥å…¨",
                    5: "æ˜ç¢ºã§æŸ”è»Ÿã«ä¸€è²«ã€‚"
                },
                "pos_examples": ["ã€Œæ„Ÿæƒ…çš„ãªç›¸æ‰‹ã«ã‚‚ä¸€å‘¼å¸ã€", "ã€Œå‘¨å›²ã®æœŸå¾…ã‚’å°Šé‡ã—ã¤ã¤è‡ªåˆ†ã®è€ƒãˆã‚’ä¼ãˆã‚‹ã€", "ã€Œè¡çªã—ã¦ã‚‚é–¢ä¿‚ã‚’åˆ‡ã‚‰ãšã«ã€è©±ã—åˆã„ã‚’ç¶šã‘ã‚ˆã†ã¨ã™ã‚‹ã€"],
                "neg_examples": ["ã€Œç›¸æ‰‹ã®æ©Ÿå«Œã§åˆ¤æ–­ãŒæºã‚Œã‚‹ã€", "ã€Œã™ãæ„è¦‹å¤‰æ›´/é€£çµ¡é®æ–­ã€", "ã€Œèª²é¡Œã‚’è‡ªåˆ†ã¨æ··åŒã€"]
            },
            "æœ¬æ¥æ€§": {
                "scale": {
                    0: "å¼·ã„è¿åˆãƒ»è‡ªå·±ç–å¤–ï¼ˆä»–è€…ã®ç›®ã«å…¨é¢ä¾å­˜ï¼‰",
                    1: "è¿åˆçš„ã§ã€è‡ªåˆ†ã‚‰ã—ã•ã‚’å„ªå…ˆã—ã«ãã„",
                    2: "æ™‚ã«æµã•ã‚Œã‚‹",
                    3: "ä¸­ç«‹",
                    4: "æ¦‚ã­ä¾¡å€¤è¦³ã«æ²¿ã†",
                    5: "ä¸€è²«ã—ã¦æ²¿ã†ã€‚"
                },
                "pos_examples": ["ã€Œå¤šæ•°æ´¾ã¨é•ã£ã¦ã‚‚ã€è‡ªåˆ†ã®ä¾¡å€¤è¦³ã«æ²¿ã£ã¦é¸ã¶ç†ç”±ã‚’è½ã¡ç€ã„ã¦èª¬æ˜ã§ãã‚‹ã€‚ã€", "ã€Œè©•ä¾¡ã‚„ãƒˆãƒ¬ãƒ³ãƒ‰ã‚ˆã‚Šã‚‚â€œè‡ªåˆ†ãŒå¤§åˆ‡ã¨æ€ã†è»¸â€ã«åŸºã¥ã„ã¦ç¶™ç¶šçš„ã«é¸æŠã—ã¦ã„ã‚‹ã€‚ã€"],
                "neg_examples": ["ã€Œâ€œäººã«ã©ã†è¦‹ã‚‰ã‚Œã‚‹ã‹â€ã§é¸æŠãŒå¤§ããå¤‰ã‚ã‚‹/ã™ãè¿åˆã—ã¦ã—ã¾ã†ã€‚ã€", "ã€Œç›¸æ‰‹ã®æ©Ÿå«Œã‚„è©•ä¾¡ã«åˆã‚ã›ã¦ã€è‡ªåˆ†ã®æœ¬å¿ƒã¨é€†ã®é¸æŠã‚’ã™ã‚‹ã“ã¨ãŒå¤šã„ã€‚ã€"]
            },
            "ä»–è€…å°Šé‡": {
                "scale": {
                    0: "ä»–è€…ã‚’å¸¸ã«è¦‹ä¸‹ã—/è»½è¦–",
                    1: "ä»–è€…ã¸ã®å°Šé‡å¼±ãåè¦‹å¤šã„",
                    2: "ä»–è€…ã‚’æ™‚ã«å°Šé‡ã§ããªã„",
                    3: "ä¸­ç«‹",
                    4: "ä»–è€…ã‚’æ¦‚ã­å°Šé‡",
                    5: "ä»–è€…ã‚’ä¸€è²«ã—ã¦å°Šé‡ã€‚"
                },
                "pos_examples": ["ã€Œé•ã„ãŒã‚ã£ã¦ã‚‚ä¾¡å€¤ã‚’èªã‚ã‚‹ã€", "ã€Œç›¸æ‰‹ã®å€‹æ€§ã‚„é¸æŠã‚’ç†è§£ã—ã‚ˆã†ã¨ã—ã€ä¸å¯§ã«æ„è¦‹ã‚’æ‰±ã†ã€"],
                "neg_examples": ["ã€Œä¾¡å€¤ãŒãªã„ã¨çƒ™å°ã€", "ã€Œæ¨©åˆ©ç„¡è¦–ã—ã¦æŠ¼ã—é€šã™ã€"]
            },
            "æ„Ÿæƒ…ã®å¼·åº¦": {
                "scale": {
                    0: "å¼·èª¿ãªã—",
                    1: "ã€Œã¨ã¦ã‚‚ã€ãªã©ã€ç©ã‚„ã‹ãªå¼·èª¿ã®ã¿",
                    2: "å¤šå°‘ã®å¼·èª¿",
                    3: "å¼·èª¿+ã€Œï¼ã€",
                    4: "å¼·èª¿å¤šç”¨/æ„Ÿå˜†",
                    5: "æ¥µç«¯ãªèª‡å¼µ/å¤šç”¨ã€‚"
                },
                "pos_examples": ["ã€Œãƒ¤ãƒã™ãã€", "ã€Œã€œã™ãã‚‹ï¼ã€", "ã€Œã€‡ã€‡ã™ãã¦æ­»ã¬ã€", "ã€Œã‚¨ã‚°ã‚¤ã€"],
                "neg_examples": ["äº‹å‹™çš„ãƒ»å„€ç¤¼çš„ãªè¡¨ç¾ã®ã¿ã€‚"]
            },
            "è¨€èªå‰µé€ æ€§": {
                "scale": {
                    0: "éŠã³çš†ç„¡",
                    1: "ã‚ãšã‹ã«ç •ã‘ãŸè¡¨ç¾",
                    2: "æ—¢å­˜ã‚¹ãƒ©ãƒ³ã‚°ãƒ»ç •ã‘ãŸè¡¨ç¾ãŒã‚„ã‚„è¦‹å—ã‘ã‚‰ã‚Œã‚‹",
                    3: "ã‚¹ãƒ©ãƒ³ã‚°ã‚„ç •ã‘ãŸè¡¨ç¾ãŒè‡ªç„¶ã«è¦‹å—ã‘ã‚‰ã‚Œã‚‹",
                    4: "ç™ºè¨€ãŒçµ‚å§‹ãã ã‘ãŸã‚¤ãƒ¡ãƒ¼ã‚¸ã§ã€ã‚¹ãƒ©ãƒ³ã‚°ã‚„é€ èªã‚‚å¤šæ•°",
                    5: "å…¨ã¦ã®ç™ºè¨€ã§é€ èªã‚„ã‚¹ãƒ©ãƒ³ã‚°ã‚’å¤šãä½¿ã£ã¦ã‚‹"
                },
                "pos_examples": ["ã€Œä»Šæ—¥ã‚‚ã€ãƒ”ã‚«ãƒ”ã‚«ãã‚“ã€ãª1æ—¥ã«ã—ã‚ˆãƒ¼ã­ï¼ã€", "ã€Œã¾ã£ã¦ã€ãã‚Œã£ã¦è¶…çµ¶ã‚­ãƒ©ã‚­ãƒ©ãƒ”ãƒ¼ãƒŠãƒƒãƒ„ãƒã‚¿ãƒ¼ã™ãã¦ã‚€ã‚Šã€"],
                "neg_examples": ["ã€Œã¨ã¦ã‚‚å…‰æ „ã«æ€ã„ã¾ã™ã€‚ã€", "ã€Œå¬‰ã—ããªã„ã¨è¨€ã£ãŸã‚‰ãªã‚Šã¾ã™ã­ã€"]
            }
        }



    def _recent_user_chars(self, history: List[Dict], user_response: str) -> str:
        """
        ç›´å‰å±¥æ­´ï¼ˆãƒ¦ãƒ¼ã‚¶ç™ºè©±ã®ã¿ï¼‰ã¨ä»Šå›ã® user_response ã‚’çµåˆã—ã€
        å¾Œã‚ã‹ã‚‰ window_chars æ–‡å­—ã‚’æŠœã
        """
        texts = [m["content"] for m in history if m.get("role") == "user"] + [user_response]
        s = "".join(texts)
        if len(s) <= self.window_chars:
            return s
        return s[-self.window_chars:]

    def _build_metric_prompt(self, display_name: str, hint: str, context_text: str) -> str:
        rubric = getattr(self, "metric_rubrics", {}).get(display_name)
        parts = [
            f"æ¬¡ã®æ—¥æœ¬èªãƒ†ã‚­ã‚¹ãƒˆã‚’èª­ã¿ã€æŒ‡æ¨™ã€Œ{display_name}ã€ã‚’0ã€œ5ç‚¹ã§æ¡ç‚¹ã—ã¦ãã ã•ã„ã€‚",
            f"ã€æŒ‡æ¨™èª¬æ˜ã€‘{hint}",
        ]
        if rubric:
            scale_lines = " / ".join(f"{k}:{v}" for k, v in rubric["scale"].items())
            pos = "ã€ã€Œ".join(rubric.get("pos_examples", []))
            neg = "ã€ã€Œ".join(rubric.get("neg_examples", []))
            parts.append(f"ã€æ¡ç‚¹åŸºæº–ã€‘{scale_lines}")
            if pos: parts.append(f"ã€é«˜ã„è¡¨ç¾ã®ä¾‹ã€‘ã€Œ{pos}ã€")
            if neg: parts.append(f"ã€ä½ã„è¡¨ç¾ã®ä¾‹ã€‘ã€Œ{neg}ã€")
        parts += [
            f"ã€æ–‡è„ˆã€‘{context_text}",
            "å‡ºåŠ›ã¯æ•°å€¤ã®ã¿ï¼ˆ0ã€œ5ã€å°æ•°ç‚¹å¯ï¼‰ã€‚ä½™è¨ˆãªæ–‡å­—ã¯å‡ºã•ãªã„ã€‚",
        ]
        return "\n".join(parts)


    def score_from_context(self, context_text: str) -> dict:
        display_scores: Dict[str, float] = {}
        for disp, hint in self.metric_prompts.items():
            prompt = self._build_metric_prompt(display_name=disp, hint=hint, context_text=context_text)
            try:
                res = self.client.chat.completions.create(
                    model=self.model,
                    messages=[{"role": "user", "content": prompt}],
                    temperature=0.6,
                    max_tokens=6,
                )
                raw = (res.choices[0].message.content or "").strip()
                m = re.search(r"([0-5](?:\.\d+)?)", raw)
                score = float(m.group(1)) if m else 0.0
            except Exception:
                score = 0.0
            display_scores[disp] = round(score, 2)

        model_scores = {DISPLAY2MODEL.get(d, d): float(v) for d, v in display_scores.items()}
        raw_y = _pls_y_from_details(model_scores)
        total = _clip_0_50(raw_y)

        return {
            "total": round(total, 2),
            "details_display": display_scores,
            "details_model": model_scores,
            "context_excerpt": context_text,
            "window_chars": len(context_text),
        }


    def score(self, history: List[Dict], user_response: str) -> Dict:
        """
        æˆ»ã‚Šå€¤ï¼š
        {
          "total": float,                 # 0-50
          "details_display": {è¡¨ç¤ºå:score},     # 0-5
          "details_model":   {å­¦ç¿’å:score},     # 0-5ï¼ˆPLSåˆæˆç”¨ï¼‰
          "context_excerpt": str,         # ä½¿ç”¨ã—ãŸæŠœç²‹
          "window_chars": int
        }
        """
        ctx = self._recent_user_chars(history, user_response)
        return self.score_from_context(ctx)   # â† ã“ã“ã ã‘ã§OKï¼ˆãƒ«ãƒ¼ãƒ–ãƒªãƒƒã‚¯ã‚‚åæ˜ ï¼‰

        # # è¡¨ç¤ºåâ†’å­¦ç¿’åã«å†™åƒ
        # model_scores: Dict[str, float] = {}
        # for disp, val in display_scores.items():
        #     key_model = DISPLAY2MODEL.get(disp, disp)
        #     model_scores[key_model] = float(val)

        # raw_y = _pls_y_from_details(model_scores)
        # total = _clip_0_50(raw_y)

        # return {
        #     "total": round(total, 2),
        #     "details_display": display_scores,
        #     "details_model": model_scores,
        #     "context_excerpt": ctx,
        #     "window_chars": min(self.window_chars, len(ctx)),
        # }

# ==========================
# LLMã®ä½¿ã„ã©ã“ã‚â‘¡ï¼šResponse
# ==========================
class Response:
    """
    - æ„å›³åˆ¤å®šï¼šç›´å‰ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›ï¼ˆã ã‘ï¼‰ã§ 1èªå‡ºåŠ›ï¼ˆadvice/question/sympathy/otherï¼‰
    - ç›®æ¨™ã‚¹ã‚³ã‚¢ï¼šç›¸æ‰‹ã®ç›´è¿‘åˆè¨ˆ +5ï¼ˆ0ã€œ50ã§ã‚¯ãƒªãƒƒãƒ—ï¼‰
    - è¿”ç­”ç”Ÿæˆï¼šSYSTEM_PROMPTã«8é …ç›®ã®è¡Œå‹•åŸå‰‡ã‚’åŸ‹ã‚è¾¼ã¿ã€çŸ­æ–‡ã‚’ç”Ÿæˆ
    - å‡ºåŠ›å¾Œãƒãƒ–ãƒ«åˆ†å‰²ï¼šã€Œã€ã€ã€Œã€‚ã€ã€Œï¼ã€ã€Œï¼Ÿã€ã¨çµµæ–‡å­—ã§ã‚¹ãƒ—ãƒªãƒƒãƒˆ
    """
    def __init__(self, client: OpenAI, model: str = "gpt-4.1", system_prompt: str = SYSTEM_PROMPT, profile: Optional[Dict] = None):
        self.client = client
        self.model = model
        # SYSTEM_PROMPTã«ãƒ—ãƒ­ãƒ•ã‚£ãƒ¼ãƒ«æƒ…å ±ã‚’åŸ‹ã‚è¾¼ã‚€
        import logging
        logging.warning("DEBUG: Response.__init__ profile = %s", profile)
        if profile:
            self.system_prompt = system_prompt.format(
                nickname=profile.get('nickname',''),
                hobby=profile.get('hobby',''),
                job=profile.get('job',''),
                personality=profile.get('personality','')
            )
        else:
            self.system_prompt = system_prompt

    def classify_intent(self, user_response: str) -> str:
        system = (
            """
            ã‚ãªãŸã¯å„ªã‚ŒãŸæ´å¯ŸåŠ›ã‚’æŒã¤ãƒ¡ãƒ³ã‚¿ãƒªã‚¹ãƒˆã§ã™ã€‚
            ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›ã‹ã‚‰ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒæ±‚ã‚ã¦ã‚‹è¿”ç­”ãŒã©ã‚Œã«è©²å½“ã—ãã†ã‹ã€ä»¥ä¸‹ã®ï¼“ã¤ã®ãƒ©ãƒ™ãƒ«ã‹ã‚‰åˆ¤æ–­ã—ãªã•ã„ã€‚
            adviceï¼ˆå…¥åŠ›ã«å¯¾ã™ã‚‹åŠ©è¨€ï¼‰
            sympathyï¼ˆå…¥åŠ›ã«å¯¾ã™ã‚‹å…±æ„Ÿãƒ»åŒæƒ…ï¼‰
            energyï¼ˆä¸Šè¨˜ï¼’ã¤ã®ã©ã¡ã‚‰ã«ã‚‚è©²å½“ã—ãªã•ãã†ãªå ´åˆï¼‰
            """
        )
        user = (
            "ã€ä»Šå›ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›ã€‘\n"
            f"{user_response}\n\n"
            "å‡ºåŠ›ã¯ä¸Šè¨˜3ãƒ©ãƒ™ãƒ«ã®ã„ãšã‚Œã‹1èªã®è‹±å˜èªï¼ˆèª¬æ˜éƒ¨åˆ†ã¯é™¤ãï¼‰ã®ã¿ã€‚"
        )
        try:
            res = self.client.chat.completions.create(
                model=self.model,
                messages=[{"role":"system","content":system},{"role":"user","content":user}],
                temperature=0.0, top_p=0.0, max_tokens=2,
            )
            raw = (res.choices[0].message.content or "").strip().lower().split()[0]
            return raw if raw in INTENT_LABELS else "other"
        except Exception:
            return "other"

    def plan_target(self, current_total: Optional[float]) -> float:
        if current_total is None:
            return 50.0
        return _clip_0_50(current_total + 5.0)

    def generate_reply(
        self,
        user_response: str,
        intent: str,
        target_score: float,
        focus_dimensions_display: List[str] = None,
        max_bubbles: int = 3,
        profile: Optional[Dict] = None,  # â†è¿½åŠ 
    ) -> List[str]:
        focus_str = ", ".join(focus_dimensions_display or [])
        style_hint = {
            "advice": "åŠ©è¨€ã€‚çµè«–ã‚’è¨€ã„åˆ‡ã‚Šã€‚1ã€œ2æ–‡ãƒ»å„20å­—ä»¥å†…ãƒ»ç®‡æ¡æ›¸ãç¦æ­¢ã€‚",
            "sympathy": "åŒæƒ…ã€‚ã¾ãšå—å®¹ã—ã¦è¶…çµ¶å¯„ã‚Šæ·»ã„ã€‚1ã€œ2æ–‡ãƒ»å„40å­—ä»¥å†…ã€‚",
            "energy": "ã¨ã‚Šã‚ãˆãšæ°—åˆ†ã‚’ç››ã‚Šä¸Šã’ã‚‹æ–‡è¨€ã‚’è¨€ã†ã€‚",
        }.get(intent, "ç›¸æ§Œ/å…±æ„Ÿã®çŸ­æ–‡ã€‚1æ–‡ãƒ»35å­—ä»¥å†…ã€‚")

        user_msg = (
            f"role=intent: {intent}\n"
            f"target_score: {target_score}\n"
            f"focus_dimensions: {focus_str if focus_str else '(è‡ªç„¶ãªãƒãƒ©ãƒ³ã‚¹)'}\n"
            f"user_response: {user_response}\n"
            "å‡ºåŠ›è¦ä»¶:\n"
            "- 1ã€œ2æ–‡ã€å„40å­—ä»¥å†…ã€‚å†—é•·ç¦æ­¢ã€‚\n"
            "- å¿…ãšãƒ¦ãƒ¼ã‚¶ãƒ¼ã®åå‰ã‚’ç©æ¥µçš„ã«å‘¼ã¶\n"
            "- ç›¸æ‰‹ã®ã“ã¨ã‚’ã€ã©ã‚“ãªã“ã¨ã§ã‚‚å¿…ãšè¤’ã‚ã‚‹\n"
            "- åŠ©è¨€/è³ªå•ã¯çµè«–ã®ã¿ã€‚åŒæƒ…ã¯ã¾ãšå—å®¹ã€‚\n"
            "- æ¯”å–©ã¯0ã€œ1å€‹ã€‚å°‚é–€ç”¨èªé€£æŠ•ãƒ»èª¬æ•™å£èª¿ã¯ç¦æ­¢ã€‚\n"
            "- å‰ã®è‡ªåˆ†ã®è¿”ç­”ã¨åŒã˜ä¸»å¼µã¯é¿ã‘ã‚‹ã€‚\n"
            "- è©±é¡Œã‚’å‹æ‰‹ã«ãã‚‰ã•ãªã„ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‹ã‚‰ä¸ãˆã‚‰ã‚ŒãŸãƒˆãƒ”ãƒƒã‚¯ã‹ã‚‰ãšã‚Œãªã„\n"
            "- çµµæ–‡å­—ã¯ä½¿ã„ã¾ãã‚‹ã“ã¨ã€‚åŒã˜çµµæ–‡å­—ã‚’æ•°å€‹ä¸¦ã¹ã¦ã‚‚è‰¯ã„ã€‚\n"
        )


        try:
            # ä¼šè©±IDã¯å‘¼ã³å‡ºã—å´ã‹ã‚‰æ¸¡ã™ã®ãŒç¶ºéº—ã ãŒã€ç°¡æ˜“ã«Cookie/remote_addrã§å–ã‚‹ãªã‚‰ã“ã†
            sid = request.cookies.get("sid") if request else None  # Flaskå†…ã§å‘¼ã¶å‰æ
            conv_id = get_or_create_conversation_id(sid or "default", profile)

            shots = sample_shots(intent, k=2, sid=sid)   # â† ã€ŒåŒæƒ…/åŠ©è¨€ã€ã”ã¨ã®çŸ­æ–‡ãƒšã‚¢


            # SYSTEMã¯åˆå›ã«ç„¼ã„ã¦ã‚ã‚‹ã®ã§ã€ä»Šå›ã¯ user ã ã‘é€ã‚‹
            payload = style_hint + "\n\n" + user_msg
            r = self.client.responses.create(
                model=self.model,
                conversation=conv_id,
                input=[*shots, {"role": "user", "content": payload}],
                temperature=0.65,
                top_p=0.9, 
                max_output_tokens=REPLY_TOKENS,
            )
            text = (r.output_text or "").strip()
        except Exception as e:
            text = f"ã”ã‚ã‚“ã€ä»Šã¡ã‚‡ã„ä¸èª¿â€¦ï¼ï¼ˆ{e}ï¼‰"


        return _bubble_split(text, max_bubbles=max_bubbles)


# ãƒ—ãƒ­ãƒ•ã‚£ãƒ¼ãƒ«å…¥åŠ›ãƒšãƒ¼ã‚¸
@app.route('/profile', methods=['GET', 'POST'])
def profile():
    if request.method == 'POST':
        # ãƒ•ã‚©ãƒ¼ãƒ ã‹ã‚‰ãƒ—ãƒ­ãƒ•ã‚£ãƒ¼ãƒ«æƒ…å ±ã‚’å–å¾—
        nickname = request.form.get('nickname')
        hobby = request.form.get('hobby')
        job = request.form.get('job')
        personality = request.form.get('personality')
        # ã‚»ãƒƒã‚·ãƒ§ãƒ³ã«ä¿å­˜
        session['profile'] = {
            'nickname': nickname,
            'hobby': hobby,
            'job': job,
            'personality': personality
        }
        # ãƒãƒ£ãƒƒãƒˆç”»é¢ã¸ãƒªãƒ€ã‚¤ãƒ¬ã‚¯ãƒˆ
        return redirect(url_for('chat'))
    return render_template('profile.html')

# ãƒãƒ£ãƒƒãƒˆç”»é¢ã®ãƒ«ãƒ¼ãƒˆ
@app.route('/chat')
def chat():
    user_profile = session.get('profile')
    # ãƒ—ãƒ­ãƒ•ã‚£ãƒ¼ãƒ«æƒ…å ±ã‚’åˆæœŸãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã«åæ˜ ã™ã‚‹å‡¦ç†ã‚’ã“ã“ã«è¿½åŠ äºˆå®š
    return render_template('gal_index.html', profile=profile)

# ãƒˆãƒƒãƒ—ãƒšãƒ¼ã‚¸ï¼ˆå¿…è¦ãªã‚‰ãƒªãƒ€ã‚¤ãƒ¬ã‚¯ãƒˆï¼‰
@app.route("/")
def index():
    return redirect(url_for('profile'))

@app.route("/ask", methods=["POST"])
def ask():
    payload = request.json or {}
    # ã‚»ãƒƒã‚·ãƒ§ãƒ³IDã¯ã‚¯ãƒƒã‚­ãƒ¼â†’ç„¡ã‘ã‚Œã°UUIDã§
    sid = request.cookies.get("sid") or payload.get("sid") or str(uuid.uuid4())
    sess = get_session(sid)
    import logging
    user_profile = session.get('profile')
    logging.warning("DEBUG: /ask profile = %s", user_profile)

    user_msg = (payload.get("message") or "").strip()
    if not user_msg:
        return jsonify({"sid": sid, "answer": "ãˆã€ãªã‚“ã¦ï¼ŸğŸ’¦"})

    # 1) ã¾ãš user ã‚’å±¥æ­´ã«ç©ã‚€ï¼ˆã“ã“ãŒæœ€å„ªå…ˆï¼‰
    sess["history"].append({"role": "user", "content": user_msg})
    sess["last_user_text"] = user_msg  # ï¼ˆä»»æ„ï¼‰ç›´è¿‘ãƒ¦ãƒ¼ã‚¶ãƒ¼ä¿æŒ

    # 2) ç›´å‰å…¥åŠ›ã ã‘è¦‹ã¦è¿”ç­”ã‚’ç”Ÿæˆï¼ˆãƒ—ãƒ­ãƒ•ã‚£ãƒ¼ãƒ«æƒ…å ±ã‚’æ¸¡ã™ï¼‰
    responder = Response(client, model="gpt-4.1", system_prompt=SYSTEM_PROMPT, profile=user_profile)
    intent = responder.classify_intent(user_msg)
    target = responder.plan_target(sess["gmd_totals"][-1] if sess.get("gmd_totals") else None)
    bubbles = responder.generate_reply(
        user_response=user_msg,
        intent=intent,
        target_score=target,
        focus_dimensions_display=[],
        max_bubbles=2,  # â† 3 â†’ 2 ã«ã—ã¦å†—é•·åŒ–ã‚’æŠ‘åˆ¶
        profile=user_profile
    )

    # 3) assistant ã¯å…ˆé ­ãƒãƒ–ãƒ«ã ã‘ä¿å­˜ï¼ˆ1ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã§OKï¼‰
    if bubbles:
        sess["history"].append({"role": "assistant", "content": bubbles[0]})
        sess["last_ai_text"] = bubbles[0]


    # è¿”å´ãƒšã‚¤ãƒ­ãƒ¼ãƒ‰ï¼ˆã¾ãšè¿”ç­”ï¼‰
    resp_payload = {"sid": sid, "answer": bubbles}

    # 4) â˜…50å­—â€œç™ºè¨€çµ‚ç«¯â€æ¡ç‚¹ï¼šå‰å›æ¡ç‚¹ä»¥é™ã®ãƒ¦ãƒ¼ã‚¶ç™ºè¨€ã ã‘ã§ã‚«ã‚¦ãƒ³ãƒˆ
    ctx, new_last_u = find_scoring_span_user_only(
        history=sess["history"],
        last_user_idx=sess.get("last_scored_user_idx", -1),
        threshold=50,
    )

    if ctx is not None:
        scorer = Scoring(client, model="gpt-4.1", window_chars=50)
        result = scorer.score_from_context(ctx)

        # ã‚»ãƒƒã‚·ãƒ§ãƒ³æ›´æ–°
        sess["last_scored_user_idx"] = new_last_u
        sess["gmd_totals"].append(result["total"])
        sess["gmd_details"].append(result["details_display"])
        sess["eval_count"] += 1

        # ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆå‘ã‘ï¼ˆæ–°å½¢å¼ gmd ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆï¼‰
        resp_payload["gmd"] = {
            "total": result["total"],
            "details": result["details_display"],
            "eval_index": sess["eval_count"] - 1,
            "context_chars": result["window_chars"],
            "context_excerpt": result["context_excerpt"],
        }

    response = jsonify(resp_payload)
    response.set_cookie("sid", sid, max_age=60*60*24*30, httponly=True, samesite="Lax")
    return response, 200

if __name__ == "__main__":
    app.run(host="0.0.0.0", port=int(os.getenv("PORT", "8080")), debug=True)
