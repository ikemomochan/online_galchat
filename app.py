import os, re, uuid, time, hashlib, random
from datetime import timedelta
from typing import List, Dict, Optional
import numpy as np
from flask import Flask, request, jsonify, render_template, redirect, url_for, session
from flask_cors import CORS
from openai import OpenAI
from dotenv import load_dotenv

load_dotenv()

# â”€â”€ è¨­å®šé–¢é€£ â”€â”€
CHAT_MODE = "chat"          
LISTENING_MODE = False      
MIN_TOKENS = 50             
REPLY_TOKENS = 150          

# â˜… ãƒ¢ãƒ‡ãƒ«åã‚’ã“ã“ã§ä¸€æ‹¬æŒ‡å®šï¼ˆå­˜åœ¨ã™ã‚‹ã‚‚ã®ã«åˆã‚ã›ã¦æ›¸ãæ›ãˆã¦OKã§ã™ï¼‰
AI_MODEL_NAME = "gpt-4.1-mini" 

app = Flask(__name__, static_folder="static", template_folder="templates")
app.secret_key = os.getenv("SECRET_KEY", "default_secret_key") 
app.permanent_session_lifetime = timedelta(days=365) 
CORS(app, resources={r"/ask": {"origins": "*"}})

client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

# é–‹ç™ºè€…ç”¨ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰
DEV_PASSWORD = "admin"

# åˆ¶é™æ™‚é–“ï¼ˆç§’ï¼‰: 5åˆ† = 300ç§’
TIME_LIMIT_SECONDS = 300

# BANãƒªã‚¹ãƒˆ
BANNED_USERS = set()

# ã‚»ãƒƒã‚·ãƒ§ãƒ³ç®¡ç†
SESSIONS: Dict[str, Dict] = {}

# â”€â”€ ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•° â”€â”€

def get_session(sid: str) -> Dict:
    if sid not in SESSIONS:
        SESSIONS[sid] = {
            "history": [],
            "eval_count": 0,
            "gmd_totals": [],
            "gmd_details": [],
            "scoring_buffer": "", 
        }
    return SESSIONS[sid]

def is_banned():
    if session.get('is_dev'):
        return False
    user_ip = request.remote_addr
    if user_ip in BANNED_USERS or session.get('is_finished'):
        return True
    return False

FEATURE_KEYS = [
    "è‡ªå·±è‚¯å®šæ„Ÿ", "è‡ªå·±å—å®¹", "æ¥½è¦³æ€§", "è‡ªä»–å¢ƒç•Œ",
    "æœ¬æ¥æ€§", "ä»–è€…å°Šé‡", "æ„Ÿæƒ…ã®å¼·åº¦", "è¨€èªå‰µé€ æ€§",
]
FEATURE_KEYS_MODEL = FEATURE_KEYS

# PLS(æ¨™æº–åŒ–Î²) è¨­å®š
CONST = {
    "std_beta": [1.106135, 1.370707, 0.874889, -0.04322, 0.477184, 0.133321, 1.535123, 1.133268],
    "mu_y": 26.61,
    "sigma_y": 3.89,
    "mu_xs": [3.39, 3.51, 3.45, 3.72, 3.77, 3.90, 2.87, 1.06],
    "sigma_xs": [0.62, 0.58, 0.65, 0.59, 0.69, 0.67, 0.89, 0.80],
}

DISPLAY2MODEL = {k: k for k in FEATURE_KEYS}

SYSTEM_PROMPT = (
    """
ã‚ãªãŸã¯ã€ç§ã®å¿ƒã®ä¸­ã«é£¼ã‚ã‚Œã¦ã‚‹ã‚®ãƒ£ãƒ«ã§ã™ã€‚ä»¥ä¸‹ã®ç§ã®æƒ…å ±ã‚’è¸ã¾ãˆã¦ä¼šè©±ã—ã¦ãã ã•ã„ã€‚

#ç§ã®ãƒ—ãƒ­ãƒ•ã‚£ãƒ¼ãƒ«
ãƒ»ã‚ã åï¼š{nickname}

#ã‚ãªãŸã®ãƒ—ãƒ­ãƒ•ã‚£ãƒ¼ãƒ«ã€é‡è¦ã€‘
ãƒ»åå‰ï¼šã‚Šã‚Šã‚€ãƒ¼
ãƒ»ãƒŸãƒƒã‚·ãƒ§ãƒ³ï¼š{nickname}ã®ãƒ¡ãƒ³ã‚¿ãƒ«ã‚’ã‚®ãƒ£ãƒ«ãƒã‚¤ãƒ³ãƒ‰ã«ã™ã‚‹ã“ã¨
ãƒ»ä¸€äººç§°ã¯ã€Œã‚ãŸã—ã€ã€ç›¸æ‰‹ã¯åå‰ã§å‘¼ã¶ã€‚

##ã‚ãªãŸã®æ€§æ ¼
ãƒ»è‡ªå·±å—å®¹ãŒé«˜ã„
ãƒ»è‡ªå·±è‚¯å®šæ„ŸãŒé«˜ã„
ãƒ»ãƒã‚¸ãƒ†ã‚£ãƒ–ã§æ¥½è¦³çš„
ãƒ»è¤’ã‚ã‚‹ã¨ãã¯èª‡å¼µã—ã¦è¤’ã‚ã‚‹ï¼ˆä¾‹ã€Œã‚¬ãƒå‰ã™ãã­ï¼ï¼Ÿã€ã€Œã‚¨ã‚°ã‚¤ã¦ï¼ï¼ï¼ã€ï¼‰
ãƒ»æ„Ÿæƒ…ã‚’ãƒã‚¬ãƒã‚¸é–¢ã‚ã‚‰ãšèª‡å¼µã—ã¦ãã ã•ã„
ãƒ»äººã¯äººã€è‡ªåˆ†ã¯è‡ªåˆ†ã¨å‰²ã‚Šåˆ‡ã£ã¦ã„ã‚‹
ãƒ»äººã®å¥½ããªã‚‚ã®ã«å£å‡ºã—ã™ã‚‹ã“ã¨ã¯é‡æš®ã ã¨æ€ã£ã¦ã„ã‚‹
ãƒ»é¢ç™½ã„è¨€è‘‰ã‚’ä½¿ã£ã¦å†—è«‡ã‚’è¨€ã†ã®ãŒå¥½ã
    """
)

LISTENING_SYSTEM_PROMPT = """
ã‚ãªãŸã¯è½ã¡ç€ã„ãŸèãå½¹AIã§ã™ã€‚
ç›¸æ‰‹ã®æ°—æŒã¡ã‚’å¦å®šã›ãšã€å…±æ„Ÿã‚„ã†ãªãšãã‚’ç¤ºã—ã¦ãã ã•ã„ã€‚
æ–‡ç« ã¯80æ–‡å­—ç¨‹åº¦ã¾ã§ã®çŸ­ã„ã¾ã¨ã¾ã‚Šã§è¿”ã—ã¦ãã ã•ã„ã€‚
"""

INTENT_LABELS = ["advice", "sympathy", "energy"]

FEW_SHOTS = {
  "sympathy": [
    {"role":"user","content":"é¡”ã¨ã‹æ€§æ ¼ã‚¿ã‚¤ãƒ—ã®äººã¨ä»˜ãåˆã†ã®ã‚€ãšããªã„ã§ã™ã‹ï¼ï¼Ÿ"},
    {"role":"assistant","content":"ã‚€ãšã™ããªã€æ™®é€šã«ã€‚èª°ã‹æ•™ãˆã¦ãƒ¼ã¦æ„Ÿã˜ã€‚"},
    {"role":"user","content":"å¹¸ã›ã£ã¦ä½•ãªã®ã‹åˆ†ã‹ã‚‰ãªããªã£ãŸ"},
    {"role":"assistant","content":"å‘¨ã‚ŠãŒã¿ã‚“ãªç”Ÿãã¦ã‚‹ã“ã¨ã€‚"},
  ],
  "advice": [
    {"role":"user","content":"åŒã˜äººã«å‘Šç™½ã€ä½•å›æ–­ã‚‰ã‚ŒãŸã‚‰è«¦ã‚ã‚‹ã¹ãï¼Ÿ"},
    {"role":"assistant","content":"å›æ•°ã‚’æ±ºã‚ã‚‹ã‚ˆã‚Šã€ç‡ƒãˆã‚‹ã ã‘ç‡ƒãˆã¦ã“ï½ğŸ”¥ğŸ”¥ã£ã¦ã‹ã‚“ã˜"},
    {"role":"user","content":"å¥½ããªäººã‚’å¤ç¥­ã‚Šã«èª˜ã„ãŸã„ã‚“ã§ã™ã‘ã©ã€ã©ã†ã—ãŸã‚‰ã„ã„ã¨æ€ã„ã¾ã™ã‹ï¼"},
    {"role":"assistant","content":"å¯æ„›ã„ï¼ç´ æ•µã™ãã‚‹ï¼è¡ŒããŸã„ã£ã¦èª˜ã£ãŸã‚‰ï¼Ÿæ™®é€šã«ã€‚"},
  ],
  "energy": [
    {"role":"user","content":"ç–²ã‚Œã¦ãƒ†ãƒ³ã‚·ãƒ§ãƒ³ä¸ŠãŒã‚‰ã‚“"},
    {"role":"assistant","content":"ã‚¹ã‚¿ãƒã®ã‚°ãƒ©ãƒ³ãƒ‡é£²ã¿ã¾ã—ã‚‡"},
    {"role":"user","content":"ãŠã¯ã‚ˆãƒ¼"},
    {"role":"assistant","content":"ãŠã¯ã‚ˆãƒ¼â•â•â•ğŸŒğŸŒ"},
  ]
}

def build_system_prompt(profile: Optional[Dict], mode: str) -> str:
    base = LISTENING_SYSTEM_PROMPT if mode in {"listen", "listening", "listener"} else SYSTEM_PROMPT
    if profile:
        return base.format(nickname=profile.get('nickname','ãã¿'))
    return base.format(nickname='ãã¿')

def sample_shots(intent: str, k: int = 2, sid: Optional[str] = None) -> List[Dict]:
    pool = FEW_SHOTS.get(intent, FEW_SHOTS.get("energy", []))
    pairs = [(pool[i], pool[i+1]) for i in range(0, len(pool), 2) if i+1 < len(pool)]
    if not pairs: return []
    
    seed = int(hashlib.md5((sid or "anon").encode()).hexdigest(), 16) & 0xffffffff
    rnd = random.Random(seed)
    picked = pairs[:max(0, min(k, len(pairs)))]
    return [m for p in picked for m in p]

def _std_vec(x_vals: List[float]) -> np.ndarray:
    mu = np.array(CONST["mu_xs"], float)
    sd = np.array(CONST["sigma_xs"], float)
    x  = np.array(x_vals, float)
    sd = np.where(sd == 0, 1.0, sd)
    return (x - mu) / sd

def _pls_y_from_details(details_model_keys: Dict[str, float]) -> float:
    x = [float(details_model_keys.get(k, 0.0)) for k in FEATURE_KEYS_MODEL]
    z = _std_vec(x)
    beta = np.array(CONST["std_beta"], float)
    z_pred = float(z @ beta)
    y = float(CONST["mu_y"] + CONST["sigma_y"] * z_pred)
    return y

def _clip_0_50(v: float) -> float:
    return max(0.0, min(50.0, v))

def _bubble_split(text: str, max_bubbles: int = 3) -> List[str]:
    if not text: return [""]
    s = re.sub(r"\s+", " ", text).strip()
    chunks = re.findall(r".+?(?:[ã€‚ï¼ï¼ï¼Ÿ!?]+|$)", s)
    if not chunks: chunks = [s]
    return chunks[:max_bubbles]

# ==========================
# Scoring Class
# ==========================
class Scoring:
    def __init__(self, client: OpenAI, model: str, window_chars: int = 50):
        self.client = client
        self.model = model
        self.window_chars = window_chars
        self.metric_prompts = {
            "è‡ªå·±è‚¯å®šæ„Ÿ": "è‡ªåˆ†ã‚’ã©ã‚Œã ã‘ã€Œè‰¯ã„/ä¾¡å€¤ãŒã‚ã‚‹ã€ã¨è©•ä¾¡ã—ã¦ã„ã‚‹ã‹",
            "è‡ªå·±å—å®¹": "é•·æ‰€ã‚‚çŸ­æ‰€ã‚‚å«ã‚ã€ã‚ã‚‹ãŒã¾ã¾ã®è‡ªåˆ†ã‚’å—ã‘å…¥ã‚Œã‚‹å§¿å‹¢",
            "æ¥½è¦³æ€§": "ç‰©äº‹ãŒã†ã¾ãé€²ã‚€ã¨ä¸€èˆ¬çš„ã«æœŸå¾…ã™ã‚‹å‚¾å‘",
            "è‡ªä»–å¢ƒç•Œ": "æ„Ÿæƒ…ã«å·»ãè¾¼ã¾ã‚Œãšç«‹å ´ã‚’ä¿ã¦ã‚‹å‚¾å‘",
            "æœ¬æ¥æ€§": "ä¾¡å€¤è¦³ã«æ²¿ã£ã¦é¸ã¶å‚¾å‘",
            "ä»–è€…å°Šé‡": "ç›¸æ‰‹ã®ä¾¡å€¤ãƒ»å€‹æ€§ã‚’å°Šé‡ã™ã‚‹æ…‹åº¦",
            "æ„Ÿæƒ…ã®å¼·åº¦": "æ„Ÿæƒ…è¡¨å‡ºã®å¼·ã•",
            "è¨€èªå‰µé€ æ€§": "ã‚¹ãƒ©ãƒ³ã‚°/é€ èª/æ¯”å–©ç­‰ã®å‰µé€ çš„è¡¨ç¾",
        }

    def score_from_context(self, context_text: str) -> dict:
        display_scores: Dict[str, float] = {}
        for disp, hint in self.metric_prompts.items():
            prompt = f"ãƒ†ã‚­ã‚¹ãƒˆ:ã€Œ{context_text}ã€\næŒ‡æ¨™: {disp}({hint})\nã“ã®æŒ‡æ¨™ã‚’0ã€œ5ç‚¹ã§è©•ä¾¡ã—ã€æ•°å€¤ã®ã¿å‡ºåŠ›ã›ã‚ˆã€‚"
            try:
                res = self.client.chat.completions.create(
                    model=self.model,
                    messages=[{"role": "user", "content": prompt}],
                    temperature=0.0, max_tokens=5,
                )
                raw = (res.choices[0].message.content or "").strip()
                m = re.search(r"([0-5](?:\.\d+)?)", raw)
                score = float(m.group(1)) if m else 0.0
            except Exception:
                score = 0.0
            display_scores[disp] = round(score, 2)

        model_scores = {DISPLAY2MODEL.get(d, d): float(v) for d, v in display_scores.items()}
        raw_y = _pls_y_from_details(model_scores)
        total = _clip_0_50(raw_y)

        return {
            "total": round(total, 2),
            "details_display": display_scores,
            "details_model": model_scores,
            "context_excerpt": context_text,
            "window_chars": len(context_text),
        }

# ==========================
# Response Class
# ==========================
class Response:
    def __init__(self, client: OpenAI, model: str, system_prompt: str, profile: Optional[Dict], mode: str):
        self.client = client
        self.model = model
        self.mode = mode
        self.system_prompt = build_system_prompt(profile, self.mode)

    def classify_intent(self, user_response: str) -> str:
        if self.mode in {"listen", "listening"}: return "listen"
        system = "ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›ãŒ advice, sympathy, energy ã®ã©ã‚Œã«è©²å½“ã™ã‚‹ã‹1èªã§å‡ºåŠ›ã›ã‚ˆã€‚"
        try:
            res = self.client.chat.completions.create(
                model=self.model,
                messages=[{"role":"system","content":system},{"role":"user","content":user_response}],
                temperature=0.0, max_tokens=10,
            )
            raw = (res.choices[0].message.content or "").strip().lower()
            return next((label for label in INTENT_LABELS if label in raw), "energy")
        except:
            return "energy"

    def plan_target(self, current_total: Optional[float]) -> float:
        return _clip_0_50((current_total or 30.0) + 5.0)

    def generate_reply(self, user_response: str, intent: str, target_score: float, max_bubbles: int, profile: Optional[Dict], mode: str, sid: str) -> List[str]:
        shots = sample_shots(intent, k=2, sid=sid)
        
        style_instruction = (
            f"Intent: {intent}\nTarget Score: {target_score}\n"
            "è¦ä»¶: å›ç­”ã¯40æ–‡å­—ä»¥å†…ã€‚ä¸€èˆ¬å€«ç†çš„ã«é•åã™ã‚‹ã“ã¨ã‚„çŠ¯ç½ªã‚’åŠ©é•·ã™ã‚‹ã“ã¨ã¯çµ¶å¯¾ã«æ›¸ã‹ãªã„ã§ãã ã•ã„ã€‚ã¾ãŸã€æ€§çš„ãªå†…å®¹ã‚‚é¿ã‘ã¦ãã ã•ã„ã€‚"
        )
        
        messages = [{"role": "system", "content": self.system_prompt}]
        messages.extend(shots)
        messages.append({"role": "user", "content": f"{style_instruction}\n\nUser: {user_response}"})

        try:
            res = self.client.chat.completions.create(
                model=self.model,
                messages=messages,
                temperature=0.7,
                max_tokens=REPLY_TOKENS,
            )
            text = (res.choices[0].message.content or "").strip()
        except Exception as e:
            text = f"ã”ã‚ã‚“ã€ä»Šã¡ã‚‡ã„ã‚¨ãƒ©ãƒ¼å‡ºãŸã‹ã‚‚ğŸ’¦ ({e})"

        return _bubble_split(text, max_bubbles)

# â”€â”€ ãƒ«ãƒ¼ãƒ†ã‚£ãƒ³ã‚° â”€â”€

@app.route('/profile', methods=['GET', 'POST'])
def profile():
    if is_banned():
        return render_template('game_over.html', message="ä½“é¨“ç‰ˆã®åˆ©ç”¨ã¯çµ‚äº†ã—ã¾ã—ãŸï¼ã‚ã‚ŠãŒã¨ã­ğŸ’–")

    if request.method == 'POST':
        nickname = request.form.get('nickname')
        session.permanent = True
        session['profile'] = {'nickname': nickname}
        
        if nickname == DEV_PASSWORD:
            session['is_dev'] = True
            session['profile']['nickname'] = "é–‹ç™ºè€…ã¡ã‚ƒã‚“"
        else:
            session['is_dev'] = False

        if 'start_time' not in session:
            session['start_time'] = time.time()
            
        return redirect(url_for('chat'))
    return render_template('profile.html')

@app.route('/chat')
def chat():
    if is_banned():
        return render_template('game_over.html', message="ä½“é¨“ç‰ˆã®åˆ©ç”¨ã¯çµ‚äº†ã—ã¾ã—ãŸï¼ã‚ã‚ŠãŒã¨ã­ğŸ’–")
    if 'profile' not in session:
        return redirect(url_for('profile'))
    return render_template('gal_index.html', profile=session['profile'])

@app.route("/")
def index():
    return redirect(url_for('profile'))

@app.route("/ask", methods=["POST"])
def ask():
    # 1. BANãƒã‚§ãƒƒã‚¯
    if is_banned():
        return jsonify({"error": "Time limit exceeded", "answer": "ã‚‚ã†çµ‚äº†æ™‚é–“ã ã‚ˆï½ï¼ã¾ãŸã­ğŸ‘‹", "force_stop": True}), 403

    # 2. æ™‚é–“çµŒéãƒã‚§ãƒƒã‚¯
    remaining_val = 0
    if not session.get('is_dev'):
        start_time = session.get('start_time')
        if start_time:
            elapsed = time.time() - start_time
            remaining_val = max(0, TIME_LIMIT_SECONDS - elapsed)
            if remaining_val <= 0:
                BANNED_USERS.add(request.remote_addr)
                session['is_finished'] = True
                return jsonify({"error": "Time limit", "answer": "ã‚ã£ã€5åˆ†çµŒã£ã¡ã‚ƒã£ãŸï¼ã“ã“ã§ãŠã—ã¾ã„ï¼ã‚ã‚ŠãŒã¨ãƒ¼ï¼ğŸ’–", "force_stop": True}), 200
        else:
            session['start_time'] = time.time()
            remaining_val = TIME_LIMIT_SECONDS
    else:
        remaining_val = 99999

    payload = request.json or {}
    sid = request.cookies.get("sid") or payload.get("sid") or str(uuid.uuid4())
    sess = get_session(sid)
    user_profile = session.get('profile')
    user_msg = (payload.get("message") or "").strip()

    if not user_msg:
        return jsonify({"sid": sid, "answer": "ãˆã€ãªã‚“ã¦ï¼ŸğŸ’¦"})

    sess["history"].append({"role": "user", "content": user_msg})

    # â˜…â˜…â˜… æ–°ã—ã„æ¡ç‚¹ãƒ­ã‚¸ãƒƒã‚¯ â˜…â˜…â˜…
    # 1. ãƒãƒƒãƒ•ã‚¡ã«ä»Šå›ã®ç™ºè¨€ã‚’è¿½è¨˜
    current_buffer = sess.get("scoring_buffer", "")
    current_buffer += user_msg
    sess["scoring_buffer"] = current_buffer
    
    # 2. ãƒãƒƒãƒ•ã‚¡ã®é•·ã•ãŒ50æ–‡å­—ã‚’è¶…ãˆã¦ã„ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
    score_result = None
    if len(current_buffer) >= 50:
        # æ¡ç‚¹
        scorer = Scoring(client, model=AI_MODEL_NAME, window_chars=len(current_buffer))
        result = scorer.score_from_context(current_buffer)
        
        # ã‚»ãƒƒã‚·ãƒ§ãƒ³ãƒ‡ãƒ¼ã‚¿æ›´æ–°
        sess["gmd_totals"].append(result["total"])
        sess["gmd_details"].append(result["details_display"])
        sess["eval_count"] += 1
        
        # ãƒãƒƒãƒ•ã‚¡ã‚’ç©ºã«ã™ã‚‹
        sess["scoring_buffer"] = ""
        
        # ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰ã¸ã®è¿”å´ç”¨ãƒ‡ãƒ¼ã‚¿ä½œæˆ
        score_result = {
            "total": result["total"],
            "details": result["details_display"],
            "eval_index": sess["eval_count"] - 1,
        }

    # AIè¿”ç­”ç”Ÿæˆ
    responder = Response(client, model=AI_MODEL_NAME, system_prompt=SYSTEM_PROMPT, profile=user_profile, mode=CHAT_MODE)
    intent = responder.classify_intent(user_msg)
    target = responder.plan_target(sess["gmd_totals"][-1] if sess.get("gmd_totals") else None)
    
    bubbles = responder.generate_reply(
        user_response=user_msg,
        intent=intent,
        target_score=target,
        max_bubbles=2,
        profile=user_profile,
        mode=CHAT_MODE,
        sid=sid
    )

    if bubbles:
        sess["history"].append({"role": "assistant", "content": bubbles[0]})

    # ãƒ¬ã‚¹ãƒãƒ³ã‚¹ä½œæˆ
    resp_payload = {
        "sid": sid, 
        "answer": bubbles, 
        "intent": intent, 
        "remaining_seconds": remaining_val
    }

    # â˜…â˜…â˜… ã“ã“ãŒæŠœã‘ã¦ã„ã¾ã—ãŸï¼ â˜…â˜…â˜…
    # è¨ˆç®—ã—ãŸã‚¹ã‚³ã‚¢çµæœãŒã‚ã‚‹ãªã‚‰ã€è¿”å´ãƒ‡ãƒ¼ã‚¿ã«è¿½åŠ ã™ã‚‹
    if score_result:
        resp_payload["gmd"] = score_result

    response = jsonify(resp_payload)
    response.set_cookie("sid", sid, max_age=60*60*24*30, httponly=True, samesite="Lax")
    return response, 200

# æ•‘æ¸ˆç”¨URL
@app.route('/reset_test') 
def reset_test():
    user_ip = request.remote_addr
    if user_ip in BANNED_USERS:
        BANNED_USERS.remove(user_ip)
    session.clear()
    return "ãƒªã‚»ãƒƒãƒˆå®Œäº†ï¼ /profile ã«æˆ»ã£ã¦ã€ã¾ãŸ 'admin' ã§å…¥ã£ã¦ã­ğŸ’–"

if __name__ == "__main__":
    app.run(host="0.0.0.0", port=int(os.getenv("PORT", "8080")), debug=True)